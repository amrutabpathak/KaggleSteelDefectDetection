{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "steel_defect_detect_defect_non_defect_cnn_reg_f1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6d9aH3sIi8r",
        "colab_type": "code",
        "outputId": "d3e68bff-47a1-42bb-d54b-59081511ec3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install keras\n",
        "!pip install opencv-python\n",
        "!pip install tensorflow-addons"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.4)\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/b0/6a1dacc2f4fab422926bfcbab6fa8f08f2a0309d872f3b059340a409b194/tensorflow_addons-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 2.8MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.17.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (3.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.1.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.33.6)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.11.2)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0->tensorflow-addons) (42.0.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.16.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/31/f944cbd5bdbcc90d5b36f0615036308c8ec1e41b4788da5b55d4900f6803/google_auth-1.8.2-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0->tensorflow-addons) (2.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.3.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2019.11.28)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.2.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.8.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow-gpu, tensorflow-addons\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed google-auth-1.8.2 tensorboard-2.0.2 tensorflow-addons-0.6.0 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOJlh4v2I_AV",
        "colab_type": "code",
        "outputId": "d8a6ecf9-c320-4772-eaaf-7a28b927db08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install tqdm\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.17.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (42.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlxDHgp6VbSm",
        "colab_type": "code",
        "outputId": "8ca41d9e-39d4-46c0-d54d-b1f720db74b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gsutil cp -r gs://steel-data/data/train.zip /content\n",
        "!unzip /content/train.zip"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://steel-data/data/train.zip...\n",
            "- [1 files][  1.2 GiB/  1.2 GiB]   64.7 MiB/s                                   \n",
            "Operation completed over 1 objects/1.2 GiB.                                      \n",
            "Copying gs://steel-data/data/train.csv...\n",
            "- [1 files][ 17.7 MiB/ 17.7 MiB]                                                \n",
            "Operation completed over 1 objects/17.7 MiB.                                     \n",
            "Copying gs://steel-data/data/sample_submission.csv...\n",
            "/ [1 files][140.7 KiB/140.7 KiB]                                                \n",
            "Operation completed over 1 objects/140.7 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4UBO2Znt2aU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "96d15f39-39d8-41b6-b9e9-4923294f6d9d"
      },
      "source": [
        "!unzip /content/train.zip "
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/train.zip\n",
            "caution: filename not matched:  /content/train/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmeLZyD8Ig11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Dropout, Conv2DTranspose, MaxPooling2D, concatenate \n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tmg3aYS47D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ONLY_CLASSIFY = True\n",
        "IMAGE_CHANNELS = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkWcb5l7Ig15",
        "colab_type": "text"
      },
      "source": [
        "## PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "Wl0Y0oqrIg16",
        "colab_type": "code",
        "outputId": "feec90d3-5f16-4011-e948-c04c983d9b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "traindf=pd.read_csv('train.csv')\n",
        "traindf['ImageId'] = traindf['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
        "traindf['ClassId'] = traindf['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n",
        "traindf['hasMask'] = ~ traindf['EncodedPixels'].isna()\n",
        "traindf.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId_ClassId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "      <th>ImageId</th>\n",
              "      <th>ClassId</th>\n",
              "      <th>hasMask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002cc93b.jpg_1</td>\n",
              "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
              "      <td>0002cc93b.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002cc93b.jpg_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0002cc93b.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0002cc93b.jpg_3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0002cc93b.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0002cc93b.jpg_4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0002cc93b.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00031f466.jpg_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00031f466.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId_ClassId  ... hasMask\n",
              "0  0002cc93b.jpg_1  ...    True\n",
              "1  0002cc93b.jpg_2  ...   False\n",
              "2  0002cc93b.jpg_3  ...   False\n",
              "3  0002cc93b.jpg_4  ...   False\n",
              "4  00031f466.jpg_1  ...   False\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7MWi9zsIg19",
        "colab_type": "code",
        "outputId": "ff56fe69-3675-4b9a-820c-fd6c1c5d9837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "maskcountdf = traindf.groupby('ImageId').agg(np.sum).reset_index()\n",
        "maskcountdf.sort_values('hasMask', ascending=False, inplace=True)\n",
        "print(maskcountdf.shape)\n",
        "maskcountdf.head()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12568, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>hasMask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10803</th>\n",
              "      <td>db4867ee8.jpg</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11776</th>\n",
              "      <td>ef24da2ba.jpg</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6284</th>\n",
              "      <td>7f30b9c64.jpg</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9421</th>\n",
              "      <td>bf0c81db6.jpg</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9615</th>\n",
              "      <td>c314f43f3.jpg</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ImageId  hasMask\n",
              "10803  db4867ee8.jpg      3.0\n",
              "11776  ef24da2ba.jpg      3.0\n",
              "6284   7f30b9c64.jpg      2.0\n",
              "9421   bf0c81db6.jpg      2.0\n",
              "9615   c314f43f3.jpg      2.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR_nhzWNIg1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_df = pd.read_csv('sample_submission.csv')\n",
        "sub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
        "test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6AK65QGIg2C",
        "colab_type": "text"
      },
      "source": [
        "## UTILITY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BsboxNrIg2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask2rle(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def rle2mask(mask_rle, shape=(256,1600)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (width,height) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9toxiVQJIg2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_masks(rles, input_shape):\n",
        "    depth = len(rles)\n",
        "    height, width = input_shape\n",
        "    masks = np.zeros((height, width, depth))\n",
        "    \n",
        "    for i, rle in enumerate(rles):\n",
        "        if type(rle) is str:\n",
        "            masks[:, :, i] = rle2mask(rle, (width, height))\n",
        "    \n",
        "    return masks\n",
        "\n",
        "def build_rles(masks):\n",
        "    width, height, depth = masks.shape\n",
        "    \n",
        "    rles = [mask2rle(masks[:, :, i])\n",
        "            for i in range(depth)]\n",
        "    \n",
        "    return rles\n",
        "\n",
        "def rles_classvect(rles):\n",
        "    depth = 2\n",
        "    masks = np.zeros((depth))\n",
        "    masks[0] = 1\n",
        "    masks[1] = 0\n",
        "    for i, rle in enumerate(rles):\n",
        "      if type(rle) is str:\n",
        "          masks[0] = 0\n",
        "          masks[1] = 1\n",
        "    return masks\n",
        "\n",
        "def random_flip(img):\n",
        "  seed = random.randint(1,5)\n",
        "  if seed % 3 == 0:\n",
        "    img = np.flip(img, 0)\n",
        "  if seed % 4 == 0:\n",
        "    img = np.flip(img, 1)\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WatdOrspIg2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lZ27V6IIg2J",
        "colab_type": "text"
      },
      "source": [
        "## Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkbZDwtwIg2J",
        "colab_type": "code",
        "outputId": "09ed1db8-8b35-483d-9609-a67f7e99d49a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#/kaggle/input/severstal-steel-defect-detection/train_images/910540b7d.jpg\n",
        "sample_filename = '910540b7d.jpg'\n",
        "sample_image_df = traindf[traindf['ImageId'] == sample_filename]\n",
        "sample_path = f\"{sample_image_df['ImageId'].iloc[0]}\"\n",
        "sample_img = cv2.imread(sample_path)\n",
        "sample_rles = sample_image_df['EncodedPixels'].values\n",
        "sample_masks = build_masks(sample_rles, input_shape=(256, 1600))\n",
        "\n",
        "fig, axs = plt.subplots(5, figsize=(12, 12))\n",
        "axs[0].imshow(sample_img)\n",
        "axs[0].axis('off')\n",
        "\n",
        "for i in range(4):\n",
        "    axs[i+1].imshow(sample_masks[:, :, i])\n",
        "    axs[i+1].axis('off')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-8f0ef95c4e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5679\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    683\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m    684\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0;32m--> 685\u001b[0;31m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         if not (self._A.ndim == 2\n",
            "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAKvCAYAAABzr+mpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWkCTR5Se5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x864 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAfhj4KcIg2M",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC__6-PXIg2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
        "                 base_path='/content/train_images',\n",
        "                 batch_size=32, dim=(256, 1600), n_channels=1,\n",
        "                 n_classes=2, random_state=2019, shuffle=True, \n",
        "                 classify=False):\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.df = df\n",
        "        self.mode = mode\n",
        "        self.base_path = base_path\n",
        "        self.target_df = target_df\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.random_state = random_state\n",
        "        self.classify = classify\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
        "        \n",
        "        X = self.__generate_X(list_IDs_batch)\n",
        "        \n",
        "        if self.mode == 'fit':\n",
        "            y = self.__generate_y(list_IDs_batch, self.classify)\n",
        "            return X, y\n",
        "        \n",
        "        elif self.mode == 'predict':\n",
        "            return X\n",
        "\n",
        "        else:\n",
        "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.seed(self.random_state)\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __generate_X(self, list_IDs_batch):\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        \n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_batch):\n",
        "            im_name = self.df['ImageId'].iloc[ID]\n",
        "            img_path = f\"{self.base_path}/{im_name}\"\n",
        "            if self.n_channels == 3:\n",
        "              img = self.__load_rgb(img_path)\n",
        "            else:\n",
        "              img = self.__load_grayscale(img_path)\n",
        "            img = random_flip(img)\n",
        "            \n",
        "            # Store samples\n",
        "            X[i,] = img\n",
        "        return X\n",
        "\n",
        "    def __generate_y(self, list_IDs_batch, classify=False):\n",
        "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
        "        if classify:\n",
        "          y = np.empty((self.batch_size, self.n_classes), dtype=int)\n",
        "        \n",
        "        for i, ID in enumerate(list_IDs_batch):\n",
        "            im_name = self.df['ImageId'].iloc[ID]\n",
        "            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n",
        "            rles = image_df['EncodedPixels'].values\n",
        "            if classify:\n",
        "              masks = rles_classvect(rles)\n",
        "            else:\n",
        "              masks = build_masks(rles, input_shape=self.dim)\n",
        "            y[i, ] = masks\n",
        "        return y\n",
        "    \n",
        "    def __load_grayscale(self, img_path):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = img.astype(np.float32) / 255.\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def __load_rgb(self, img_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = img.astype(np.float32) / 255.\n",
        "        return img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsrlhlZHIg2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    maskcountdf.index, random_state=2019, test_size=0.15\n",
        ")\n",
        "\n",
        "train_generator = DataGenerator(\n",
        "    train_idx, \n",
        "    df=maskcountdf,\n",
        "    target_df=traindf,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    n_classes=2,\n",
        "    n_channels=IMAGE_CHANNELS,\n",
        "    classify=ONLY_CLASSIFY\n",
        ")\n",
        "\n",
        "val_generator = DataGenerator(\n",
        "    val_idx, \n",
        "    df=maskcountdf,\n",
        "    target_df=traindf,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    n_classes=2,\n",
        "    n_channels=IMAGE_CHANNELS,\n",
        "    classify=ONLY_CLASSIFY\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkjrPJMsG-3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def F1Score(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nwZIG7uIg2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    weight_decay = 1e-3\n",
        "\n",
        "    c1 = Conv2D(8, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(weight_decay)) (inputs)\n",
        "    #c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
        "    b1 = BatchNormalization() (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (b1)\n",
        "    \n",
        "\n",
        "    c2 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(weight_decay)) (p1)\n",
        "    #c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
        "    b2 = BatchNormalization() (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (b2)\n",
        "    \n",
        "\n",
        "    c3 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(weight_decay)) (p2)\n",
        "    #c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
        "    b3 = BatchNormalization() (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (b3)\n",
        "    #d3 = Dropout(0.3) (p3)\n",
        "\n",
        "    c4 = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(weight_decay)) (p3)\n",
        "    #c4 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
        "    b4 = BatchNormalization() (c4)\n",
        "    p4 = MaxPooling2D((2, 2)) (b4)\n",
        "\n",
        "    c5 = Conv2D(8, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(weight_decay)) (p4)\n",
        "    b5 = BatchNormalization() (c5)\n",
        "    #c5 = Conv2D(8, (3, 3), activation='relu', padding='same') (c5)\n",
        "    p5 = MaxPooling2D((2, 2)) (b5)\n",
        "    #d5 = Dropout(0.3) (p5)\n",
        "\n",
        "    f6 = Flatten() (p5)\n",
        "    #d6 = Dense(16, activation='softmax') (f6)\n",
        "    d6 = Dense(2, activation='softmax') (f6)\n",
        "\n",
        "    outputs = d6\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.SGD(), \n",
        "        loss=keras.losses.categorical_crossentropy, \n",
        "        metrics=[F1Score])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqSfynzbIg2R",
        "colab_type": "code",
        "outputId": "1828b001-8d9f-408c-86ea-765c31a8dddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        }
      },
      "source": [
        "model = build_model((256, 1600, 1))\n",
        "model.summary()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 256, 1600, 1)]    0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 256, 1600, 8)      80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 256, 1600, 8)      32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 128, 800, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 128, 800, 16)      1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 128, 800, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 64, 400, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 64, 400, 32)       4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 64, 400, 32)       128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 32, 200, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 32, 200, 16)       4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 32, 200, 16)       64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 16, 100, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 16, 100, 8)        1160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 16, 100, 8)        32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 8, 50, 8)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 6402      \n",
            "=================================================================\n",
            "Total params: 18,394\n",
            "Trainable params: 18,234\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUUQWt-vIg2T",
        "colab_type": "code",
        "outputId": "3f23d04f-054c-4265-b0f1-8fb32f92589f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'simple_cnn_reg_model.h5', \n",
        "    monitor='F1Score', \n",
        "    verbose=0, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint],\n",
        "    use_multiprocessing=True,\n",
        "    epochs=70\n",
        ")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "666/667 [============================>.] - ETA: 0s - loss: 0.8683 - F1Score: 0.6634Epoch 1/70\n",
            "667/667 [==============================] - 300s 449ms/step - loss: 0.8683 - F1Score: 0.6634 - val_loss: 0.7331 - val_F1Score: 0.6683\n",
            "Epoch 2/70\n",
            "667/667 [==============================] - 298s 446ms/step - loss: 0.5980 - F1Score: 0.7329 - val_loss: 0.5983 - val_F1Score: 0.7436\n",
            "Epoch 3/70\n",
            "667/667 [==============================] - 297s 445ms/step - loss: 0.5387 - F1Score: 0.7677 - val_loss: 0.7169 - val_F1Score: 0.6725\n",
            "Epoch 4/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.5000 - F1Score: 0.7974 - val_loss: 0.4993 - val_F1Score: 0.7874\n",
            "Epoch 5/70\n",
            "667/667 [==============================] - 297s 446ms/step - loss: 0.4772 - F1Score: 0.8072 - val_loss: 0.5442 - val_F1Score: 0.7639\n",
            "Epoch 6/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.4503 - F1Score: 0.8228 - val_loss: 0.9989 - val_F1Score: 0.6859\n",
            "Epoch 7/70\n",
            "667/667 [==============================] - 298s 446ms/step - loss: 0.4301 - F1Score: 0.8349 - val_loss: 0.9937 - val_F1Score: 0.6747\n",
            "Epoch 8/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.4212 - F1Score: 0.8379 - val_loss: 0.7171 - val_F1Score: 0.7185\n",
            "Epoch 9/70\n",
            "667/667 [==============================] - 298s 446ms/step - loss: 0.4053 - F1Score: 0.8513 - val_loss: 1.3296 - val_F1Score: 0.6207\n",
            "Epoch 10/70\n",
            "667/667 [==============================] - 298s 446ms/step - loss: 0.4001 - F1Score: 0.8504 - val_loss: 0.5737 - val_F1Score: 0.7612\n",
            "Epoch 11/70\n",
            "667/667 [==============================] - 298s 446ms/step - loss: 0.3852 - F1Score: 0.8580 - val_loss: 0.4649 - val_F1Score: 0.8184\n",
            "Epoch 12/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.3842 - F1Score: 0.8549 - val_loss: 4.8448 - val_F1Score: 0.4637\n",
            "Epoch 13/70\n",
            "667/667 [==============================] - 297s 445ms/step - loss: 0.3707 - F1Score: 0.8653 - val_loss: 0.8799 - val_F1Score: 0.6704\n",
            "Epoch 14/70\n",
            "667/667 [==============================] - 297s 445ms/step - loss: 0.3573 - F1Score: 0.8704 - val_loss: 3.9608 - val_F1Score: 0.4712\n",
            "Epoch 15/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.3516 - F1Score: 0.8754 - val_loss: 2.9348 - val_F1Score: 0.4749\n",
            "Epoch 16/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.3442 - F1Score: 0.8746 - val_loss: 1.0594 - val_F1Score: 0.6319\n",
            "Epoch 17/70\n",
            "667/667 [==============================] - 297s 445ms/step - loss: 0.3427 - F1Score: 0.8737 - val_loss: 1.0629 - val_F1Score: 0.5769\n",
            "Epoch 18/70\n",
            "667/667 [==============================] - 297s 445ms/step - loss: 0.3326 - F1Score: 0.8821 - val_loss: 1.5344 - val_F1Score: 0.5887\n",
            "Epoch 19/70\n",
            "667/667 [==============================] - 297s 446ms/step - loss: 0.3228 - F1Score: 0.8856 - val_loss: 0.8747 - val_F1Score: 0.6971\n",
            "Epoch 20/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.3138 - F1Score: 0.8905 - val_loss: 0.8049 - val_F1Score: 0.7292\n",
            "Epoch 21/70\n",
            "667/667 [==============================] - 298s 448ms/step - loss: 0.3107 - F1Score: 0.8936 - val_loss: 4.1189 - val_F1Score: 0.4850\n",
            "Epoch 22/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.3093 - F1Score: 0.8896 - val_loss: 0.7040 - val_F1Score: 0.7532\n",
            "Epoch 23/70\n",
            "667/667 [==============================] - 297s 445ms/step - loss: 0.2992 - F1Score: 0.8941 - val_loss: 0.4161 - val_F1Score: 0.8526\n",
            "Epoch 24/70\n",
            "667/667 [==============================] - 296s 444ms/step - loss: 0.3005 - F1Score: 0.8985 - val_loss: 0.3515 - val_F1Score: 0.8665\n",
            "Epoch 25/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2861 - F1Score: 0.9051 - val_loss: 0.3711 - val_F1Score: 0.8627\n",
            "Epoch 26/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.2940 - F1Score: 0.8996 - val_loss: 1.5080 - val_F1Score: 0.5951\n",
            "Epoch 27/70\n",
            "667/667 [==============================] - 297s 446ms/step - loss: 0.2982 - F1Score: 0.8964 - val_loss: 1.1801 - val_F1Score: 0.6886\n",
            "Epoch 28/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2841 - F1Score: 0.8979 - val_loss: 1.3193 - val_F1Score: 0.6565\n",
            "Epoch 29/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2687 - F1Score: 0.9095 - val_loss: 0.8720 - val_F1Score: 0.7249\n",
            "Epoch 30/70\n",
            "667/667 [==============================] - 297s 445ms/step - loss: 0.2674 - F1Score: 0.9101 - val_loss: 1.8374 - val_F1Score: 0.5694\n",
            "Epoch 31/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2705 - F1Score: 0.9095 - val_loss: 1.2722 - val_F1Score: 0.6549\n",
            "Epoch 32/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2596 - F1Score: 0.9102 - val_loss: 2.7144 - val_F1Score: 0.5166\n",
            "Epoch 33/70\n",
            "667/667 [==============================] - 297s 446ms/step - loss: 0.2693 - F1Score: 0.9092 - val_loss: 0.5680 - val_F1Score: 0.7874\n",
            "Epoch 34/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.2522 - F1Score: 0.9137 - val_loss: 0.3479 - val_F1Score: 0.8771\n",
            "Epoch 35/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.2495 - F1Score: 0.9170 - val_loss: 1.0730 - val_F1Score: 0.6250\n",
            "Epoch 36/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.2470 - F1Score: 0.9187 - val_loss: 1.0189 - val_F1Score: 0.7308\n",
            "Epoch 37/70\n",
            "667/667 [==============================] - 300s 449ms/step - loss: 0.2405 - F1Score: 0.9200 - val_loss: 1.2487 - val_F1Score: 0.6993\n",
            "Epoch 38/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2405 - F1Score: 0.9220 - val_loss: 0.7739 - val_F1Score: 0.7265\n",
            "Epoch 39/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2341 - F1Score: 0.9214 - val_loss: 1.9521 - val_F1Score: 0.5753\n",
            "Epoch 40/70\n",
            "667/667 [==============================] - 297s 445ms/step - loss: 0.2340 - F1Score: 0.9268 - val_loss: 0.8319 - val_F1Score: 0.7479\n",
            "Epoch 41/70\n",
            "667/667 [==============================] - 297s 445ms/step - loss: 0.2370 - F1Score: 0.9218 - val_loss: 1.8574 - val_F1Score: 0.6469\n",
            "Epoch 42/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2257 - F1Score: 0.9268 - val_loss: 1.4803 - val_F1Score: 0.6816\n",
            "Epoch 43/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.2220 - F1Score: 0.9303 - val_loss: 1.7784 - val_F1Score: 0.6656\n",
            "Epoch 44/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2287 - F1Score: 0.9240 - val_loss: 2.3904 - val_F1Score: 0.5112\n",
            "Epoch 45/70\n",
            "667/667 [==============================] - 298s 446ms/step - loss: 0.2268 - F1Score: 0.9277 - val_loss: 0.3806 - val_F1Score: 0.8632\n",
            "Epoch 46/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.2157 - F1Score: 0.9340 - val_loss: 1.1174 - val_F1Score: 0.7131\n",
            "Epoch 47/70\n",
            "667/667 [==============================] - 299s 449ms/step - loss: 0.2267 - F1Score: 0.9262 - val_loss: 1.4379 - val_F1Score: 0.6870\n",
            "Epoch 48/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.2170 - F1Score: 0.9318 - val_loss: 1.5843 - val_F1Score: 0.6800\n",
            "Epoch 49/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2145 - F1Score: 0.9318 - val_loss: 1.2051 - val_F1Score: 0.6725\n",
            "Epoch 50/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.2146 - F1Score: 0.9345 - val_loss: 0.3616 - val_F1Score: 0.8787\n",
            "Epoch 51/70\n",
            "667/667 [==============================] - 300s 449ms/step - loss: 0.2163 - F1Score: 0.9319 - val_loss: 1.2723 - val_F1Score: 0.6736\n",
            "Epoch 52/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2115 - F1Score: 0.9319 - val_loss: 2.2125 - val_F1Score: 0.6394\n",
            "Epoch 53/70\n",
            "667/667 [==============================] - 299s 449ms/step - loss: 0.2041 - F1Score: 0.9383 - val_loss: 0.7965 - val_F1Score: 0.7548\n",
            "Epoch 54/70\n",
            "667/667 [==============================] - 300s 450ms/step - loss: 0.2082 - F1Score: 0.9358 - val_loss: 1.8224 - val_F1Score: 0.5812\n",
            "Epoch 55/70\n",
            "667/667 [==============================] - 300s 450ms/step - loss: 0.2012 - F1Score: 0.9383 - val_loss: 1.3107 - val_F1Score: 0.6239\n",
            "Epoch 56/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.2093 - F1Score: 0.9378 - val_loss: 0.5830 - val_F1Score: 0.8130\n",
            "Epoch 57/70\n",
            "667/667 [==============================] - 300s 450ms/step - loss: 0.2071 - F1Score: 0.9355 - val_loss: 0.2976 - val_F1Score: 0.9022\n",
            "Epoch 58/70\n",
            "667/667 [==============================] - 300s 450ms/step - loss: 0.1985 - F1Score: 0.9411 - val_loss: 0.8746 - val_F1Score: 0.7302\n",
            "Epoch 59/70\n",
            "667/667 [==============================] - 297s 446ms/step - loss: 0.1913 - F1Score: 0.9455 - val_loss: 1.2500 - val_F1Score: 0.6571\n",
            "Epoch 60/70\n",
            "667/667 [==============================] - 298s 446ms/step - loss: 0.1973 - F1Score: 0.9398 - val_loss: 0.6696 - val_F1Score: 0.8018\n",
            "Epoch 61/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.2122 - F1Score: 0.9355 - val_loss: 0.6664 - val_F1Score: 0.7901\n",
            "Epoch 62/70\n",
            "667/667 [==============================] - 300s 449ms/step - loss: 0.1995 - F1Score: 0.9431 - val_loss: 3.8880 - val_F1Score: 0.6116\n",
            "Epoch 63/70\n",
            "667/667 [==============================] - 299s 449ms/step - loss: 0.1974 - F1Score: 0.9426 - val_loss: 0.5862 - val_F1Score: 0.8210\n",
            "Epoch 64/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.1890 - F1Score: 0.9440 - val_loss: 1.8642 - val_F1Score: 0.6629\n",
            "Epoch 65/70\n",
            "667/667 [==============================] - 300s 449ms/step - loss: 0.1892 - F1Score: 0.9471 - val_loss: 2.6874 - val_F1Score: 0.6421\n",
            "Epoch 66/70\n",
            "667/667 [==============================] - 298s 446ms/step - loss: 0.1827 - F1Score: 0.9478 - val_loss: 2.5126 - val_F1Score: 0.6277\n",
            "Epoch 67/70\n",
            "667/667 [==============================] - 299s 448ms/step - loss: 0.1862 - F1Score: 0.9457 - val_loss: 0.3482 - val_F1Score: 0.8921\n",
            "Epoch 68/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.1882 - F1Score: 0.9463 - val_loss: 0.8065 - val_F1Score: 0.7334\n",
            "Epoch 69/70\n",
            "667/667 [==============================] - 298s 447ms/step - loss: 0.1963 - F1Score: 0.9450 - val_loss: 0.3838 - val_F1Score: 0.8825\n",
            "Epoch 70/70\n",
            "667/667 [==============================] - 299s 449ms/step - loss: 0.1786 - F1Score: 0.9502 - val_loss: 1.0959 - val_F1Score: 0.7569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP2YJN65rpdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/simple_cnn_reg_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}